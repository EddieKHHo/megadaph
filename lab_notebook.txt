Fenner Macrae Megadaph Lab Notebook
===============================================================================
# vim: textwidth=79

Logs of specific commands run can be found in analysis directories.

===============================================================================
August 21st, 2017
===============================================================================

-------------------------------------------------------------------------------
Summary of project so far:
-------------------------------------------------------------------------------
- Emily has trimmed and merged reads (~/megadaph/reads/cleaned_reads/)

- Emily has produced draft assemblies for all starting controls using SPAdes
  (~/megadaph/assembly/spades_Aug2017/)

- I constructed a Kraken (https://ccb.jhu.edu/software/kraken/) database
containing all complete prokaryotic refseq assemblies
(~/megadaph/decontamination/kraken/db/). Kraken's database build scripts are
out of date, so I used a user produced set of scripts
(https://github.com/mw55309/Kraken_db_install_scripts). Protocol was followed
from (http://www.opiniomics.org/building-a-kraken-database-with-new-ftp-\
structure-and-no-gi-numbers/)

- I also downloaded the prebuilt full nt database for Centrifuge
  (https://ccb.jhu.edu/software/centrifuge)

-------------------------------------------------------------------------------
Activity Log for today:
-------------------------------------------------------------------------------
- Ran centrifuge on cleaned FA_SC reads
  (~/megadaph/decontamination/centrifuge/reads) and the D. magna reference
assembly (~/megadaph/decontamination/centrifuge/reference_assembly). Used the
complete nt centrifuge database but excluded arthropods and bony fish. The
taxonomic IDs for these groups were found by examining
~/megadaph/decontamination/centrifuge/custom_db/taxonomy/names.dmp.


===============================================================================
August 22nd, 2017 - August 23rd, 2017
===============================================================================
- Constructed a custom centrifuge database using protocol from centrifuge
manual. All Bacterial, Plant, Protozoan, Archael and Fungal genomes classified
as 'Complete' by NCBI were included, as well as the human reference.

===============================================================================
August 23rd, 2017
===============================================================================
- Created an R package fen.R.util (https://github.com/fennerm/fen.R.util) to
house code shared between other R packages. Decided to make it separate to the
bioinformatics_scripts repo since it will primarily be updated from my personal
machine.

-------------------------------------------------------------------------------
Preliminary Centrifuge Analysis Of D. magna reference assembly
-------------------------------------------------------------------------------
(~/megadaph/decontamination/centrifuge/reference_assembly)
- Wrote R functions for adding taxonomic name, and match fraction to the
centrifuge output file.

Taxa with strong evidence for contamination:
- Thermus thermophilus (From Taq polymerase?)
- Homo sapiens
- Limnohabitans
- Plant of some kind (hits to tomato, rice, cucumber etc.)
- Parasitic worm (Trichobilharzia, Spirometra, Echinostoma, Protopolystoma,
Schistosoma)

===============================================================================
August 24th, 2017
===============================================================================
-------------------------------------------------------------------------------
Decontamination Strategy (to be continuously updated)
-------------------------------------------------------------------------------
- Identify confident contaminants with centrifuge and remove
- Reassemble and run centrifuge on assembly
- Use GC content and coverage to remove additional suspicious contigs
(See Koutsovoulos et al., 2016)
- Exclude contigs below 500bp
(See Koutsovoulos et al., 2016)
- Figure out plan for checking that assembly isn't overcleaned.
- Check for differences in relative coverage between different starting control
assemblies!
- Check for dramatic shifts in coverage across potential misassemblies

===============================================================================
August 25th, 2017
===============================================================================
Planned analysis:
- Goal: Produce confidence metric for centrifuge classifications.
- Strategy: Scramble all of the nucleotides in the fasta input to centrifuge.
Then run centrifuge. This will give us our expectations under the null.
- Wrote a script to scramble all of the sequences in a multifasta file
(fmacrae/code/R/scripts/scramble_fasta.R)
- Started test run of analysis on FA_SC in
megadaph/decontamination/centrifuge/null_distribution
- Found a bunch of false positive hits. A bunch to human, sheep, tomato etc.
Basically all large genomes. Largest hit score was only 289 though, so
filtering by score should be pretty easy and effective.

===============================================================================
August 28th, 2017
===============================================================================
- Large reorganization of project github. Local and IBEST directories should
now be kept fairly well in sync using github. Data will still reside only on
IBEST.
- Wrote the alignment function for the megadaph pipeline
(fmacrae/code/util/python_modules/run_bowtie2.py)

===============================================================================
August 29th, 2017
===============================================================================
- Added run_index_fasta module to the Megadaph decontamination pipeline.
- Added CheckedArgs class module to validate arguments passed to the pipeline.
- Added unit tests directory, and got testing working for CheckedArgs

===============================================================================
August 30th, 2017
===============================================================================
- Setup my personal python modules as a package (fmbiopy) for easier import and
extensibility.
	- Using pytest for package testing (https://docs.pytest.org/en/latest/)

- Plan to set up fmbiopy and bioinformatics_scripts as subtrees of the Megadaph
repository, but the version of git on IBEST is super out of date. Messaged
Benji about getting a new version. Will use
https://medium.com/@porteneuve/mastering-git-subtrees-943d29a798ec as a guide
for subtree set up.

===============================================================================
August 31st, 2017
===============================================================================
- Fixed bugs in run_bowtie2.py, run_index_fasta.py and fen_util.run_command().
All tests now passing
- Came up with an object oriented pipeline structure. Basically will define
pipeline and submodule classes which will automatically handle argument
passing, logging and argument checking.
- Benji made an updated git module but its only available for some of the
servers until they update the rest. Don't know how long this will take but I'll
put off getting the subtree properly set up for the time being
- Read about pytest features:
http://pythontesting.net/framework/pytest/pytest-fixtures-nuts-bolts/#bare

===============================================================================
September 3rd, 2017
===============================================================================
- Partially created BioFileGroup class for housing and type checking
bioinformatics files within the pipeline (~/fmacrae/code/fmbiopy/fmbiopy.py).
Some tests still failing. Tomorrow will start by refactoring the prevalidation
functions.

===============================================================================
September 4th, 2017
===============================================================================
- Added a bunch of classes to BioFileGroup.

===============================================================================
September 5th, 2017
===============================================================================
- Added further classes to BioFileGroup. Now just need to implement an
IndexedFasta class and I can move onto the pipeline code.
- IndexedFasta implemented. Documentation could still use a little work but
biofile.py is basically complete.
- Installed pydocstring plugin for easy documentation in reST formatting. Call
with :Pydocstring in vim while cursor is on function or class definition.
- Thought a lot about what docstring style to use from now on. Decided on numpy
style for the following reasons:
	- Ease of reading
	- Can use 'pyment -wo "numpydoc" <file.py>' to automate much of the process
	- Can be converted into documentation with Sphinx
	- Guidelines:
	  http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html

===============================================================================
September 6th, 2017
===============================================================================
- Think I might have reinvented the wheel a bit with biofile. Ruffus seems like
it includes the same functionality and more.
- New plan: Next step rewrite bowtie2_align.py and index_fasta.py as ruffus
functions
- Interrupted while working: currently working on editing the .vimrc to auto-
open split tabs with python environment

===============================================================================
September 7th, 2017
===============================================================================
- Officially switched over to Ruffus for pipelining.
- Set up Ruffus logging class in fmbiopy.fmruffus

===============================================================================
September 10th, 2017
===============================================================================
- Wrote and tested following tasks in fmbiopy.ruffus_tasks: bowtie_index_fasta,
samtools_index_fasta, gunzip, gzip, paired_bowtie2_align

===============================================================================
September 11th, 2017
===============================================================================
- Spent a while trying to get jedi-vim to play nice with vim 8 and pyenv.
Eventually got it to work by adding a script to .vim/after/ftplugin/python.vim,
and adding an __init__.py to fmbiopy.fmbiopy
- Started on the decontam_pipeline proper in
  'fmacrae/megadaph/decontam_pipeline'. Decided to structure as a script rather
than a package.
- Started adding some additional functionality to biofile, so that it can be
used for checking argument validity in the pipeline.

===============================================================================
September 13th, 2017
===============================================================================
- Ideas from meeting
- Primers arrived
- Meeting with Sarah: Updated on progress. We shared a little concern about
Emily using hard GC content/coverage cutoffs for filtering contamination in the
assemblies. She showed me Emily's assembly stats though and they were super
impressive. Very large N50s and a pretty consistent total assembly length
~130-180 Mb.
- Lab meeting: Introductions - my presentation slot set for Nov. 29th
- Met with Emily about assembly progress. We talked about the hard cutoff
criteria issue. I suggested running the published reference genome through her
filter and see how much is lost. A nontrivial amount was excluded - large
enough that I would be uncomfortable using these filters for the mutation
calling pipeline. However we agreed they are probably fine for the TE detection
if she is comfortable with them. Given her timeframe, she probably doesn't have
the time to work at my snailpace. I asked her about her assembly parameters so
that I could eventually include them in the Ruffus pipeline.


===============================================================================
September 24th, 2017
===============================================================================
Been having troubles getting vim and pyenv to work with the new server
infrastructure which Benji is updating. Recompiled vim with following commands:

pyenv local 3.5.2

./configure --prefix=$HOME --with-features=huge --enable-multibyte
--enable-cscope=yes ---enable-pythoninterp=dynamic
--with-python3-config-dir=/opt/modules/devel/python/2.7.10/lib/python2.7/config
--enable-python3interp=dynamic
--with-python3-config-dir=/opt/modules/devel/python/3.5.2/lib/python3.5/config-3.5m/
--disable-gui

make VIMRUNTIMEDIR=$HOME/.vim

This worked to get vim working with python3 sort of, but broke python2. Also
syntax highlighting stopped working.

Decided to just switch to Neovim to avoid these issues. First installed
linuxbrew. Linuxbrew complained about our git version being out of date.
Attempted to update it using 'linuxbrew install git', but its throwing the
following error:

/mnt/lfs2/schaack/.linuxbrew/bin/ld: cannot find -ldb
collect2: error: ld returned 1 exit status

===============================================================================
September 25th, 2017
===============================================================================
Installed a brewed version of perl with linuxbrew.

===============================================================================
September 27th, 2017
===============================================================================
Installed brewed versions of git and neovim.

===============================================================================
September 28th, 2017
===============================================================================
Neovim up and running. Installed vim-plug for managing plugins. Added Ale for
syntax checking and vim-test for testing code in nvim.

===============================================================================
September 29th, 2017
===============================================================================
Refactored my dotfile set up so that my custom dotfiles are copied over ssh
upon login. This means that any changes to my dotfiles wont affect other users
and can also be more easily transferred to new servers.

Finally got neovim to run entirely without errors with my setup.

===============================================================================
October 2nd, 2017
===============================================================================
Spent all day bug fixing the decontamination pipeline

===============================================================================
October 4th, 2017
===============================================================================
Finally finished bugfixing on fmruffus module. Architecture for running Ruffus
tasks is now pretty solid. Should now be fairly simple to add new Ruffus tasks.
Next step is to get a basic pipeline running with just the initial Bowtie2
alignment to get a feel for how Ruffus pipeline scripts work.
pipeline script to start running.
