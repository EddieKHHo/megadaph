"""Megadaph Decontamination Pipeline"""

import os
from shutil import rmtree

# ==============================================================================
# Set up
# ==============================================================================
configfile: "config.yml"

SAMPLE, PAIR = glob_wildcards(
        os.path.join(config['readsdir'], '{sample}.{pair}.fastq.gz'))

# Remove duplicate entries
SAMPLE = sorted(list(set(SAMPLE)))

# Genotype indices given by first two letters of sample name
GENOTYPE = list(set([x[0:2] for x in SAMPLE]))

# ==============================================================================
# Helper functions
# ==============================================================================

def get_assembly1_bams_from_genotype(wildcards):
    sample_names = get_samples_for_genotype(wildcards)
    bam_files = ["output/align_to_assembly1/" + x + ".bam"
                 for x in sample_names]
    return bam_files


def get_samples_for_genotype(wildcards):
    return [x for x in SAMPLE if x.startswith(wildcards.genotype)]


def get_starting_control(wildcards):
    """Given a sample ID, return the ID of its starting control"""
    return wildcards.sample[0:2] + "SC"


def match_assembly(wildcards):
    """Given the sample, return the starting control assembly"""
    starting_control = get_starting_control(wildcards)
    return os.path.join("output", "length_filter_assembly1",
                        starting_control + ".fasta")


def match_assembly_index(wildcards):
    """Given the sample, return the starting control assembly bowtie2 index"""
    starting_control = get_starting_control(wildcards)
    return os.path.join("output", "length_filter_assembly1",
                        starting_control + ".1.bt2")

def bowtie2_idx_root(idx):
  """Given the path to a forward bowtie2 index, return its root name"""
  return os.path.splitext(os.path.splitext(idx)[0])[0]

# ==============================================================================
# Pipeline
# ==============================================================================
rule all:
    input:
        'output/multiqc/multiqc.html',
        expand('output/align_to_assembly1/{sample}.bam', sample=SAMPLE),
        expand("output/init_blobtools_database1/{genotype}.blobDB.json",
                genotype=GENOTYPE)

rule raw_fastqc:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        'output/raw_fastqc/{sample}.R1_fastqc.html',
        'output/raw_fastqc/{sample}.R2_fastqc.html',
    params:
        outdir = 'output/raw_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads}"


rule trim_adapters:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    log: "output/trim_adapters/log/{sample}.log"
    threads: 10
    params:
        ref = config['adapters'],
        k = '23',
        ktrim = 'r',
        mink = '4',
        hdist = '1'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.fwd_reads} out2={output.rev_reads} ref={params.ref} "
        "k={params.k} ktrim={params.ktrim} mink={params.mink} "
        "hdist={params.hdist} threads={threads} tpe tbo 2> {log}"


rule merge_reads:
    input:
        fwd_reads = rules.trim_adapters.output.fwd_reads,
        rev_reads = rules.trim_adapters.output.rev_reads
    output:
        fwd_reads = 'output/merge_reads/{sample}.R1.fastq.gz',
        rev_reads = 'output/merge_reads/{sample}.R2.fastq.gz',
        merged_reads = 'output/merge_reads/{sample}.merged.fastq.gz',
        insert_hist = 'output/merge_reads/{sample}.hist'
    log: "output/merge_reads/log/{sample}.log"
    params:
        vstrict = 't'
    shell:
        "bbmerge.sh in1={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.merged_reads} outu={output.fwd_reads} "
        "outu2={output.rev_reads} ihist={output.insert_hist} "
        "vstrict={params.vstrict} 2> {log}"


rule quality_trim:
    input:
        fwd_reads = rules.merge_reads.output.fwd_reads,
        rev_reads = rules.merge_reads.output.rev_reads,
        merged_reads = rules.merge_reads.output.merged_reads
    output:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        merged_reads = 'output/quality_trim/{sample}.merged.fastq.gz'
    log:
        paired = "output/quality_trim/log/{sample}.paired.log",
        unpaired = "output/quality_trim/log/{sample}.unpaired.log"
    threads: 10
    params:
        qtrim = 'rl',
        trimq = '20',
        minlen = '50'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} "
        "out={output.fwd_reads} out2={output.rev_reads} threads={threads} "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "2> {log.paired} &&"
        "bbduk.sh in={input.merged_reads} out={output.merged_reads} "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "threads={threads} 2> {log.unpaired}"


rule clean_fastqc:
    input:
        fwd_reads = rules.quality_trim.output.fwd_reads,
        rev_reads = rules.quality_trim.output.rev_reads,
        merged_reads = rules.quality_trim.output.merged_reads
    output:
        'output/clean_fastqc/{sample}.R1_fastqc.html',
        'output/clean_fastqc/{sample}.R2_fastqc.html',
        'output/clean_fastqc/{sample}.merged_fastqc.html'
    params:
        outdir='output/clean_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads} "
        "{input.merged_reads}"


rule multiqc:
    input:
        expand('output/clean_fastqc/{sample}.R1_fastqc.html', sample=SAMPLE),
        expand('output/clean_fastqc/{sample}.R2_fastqc.html', sample=SAMPLE),
        expand(
            'output/clean_fastqc/{sample}.merged_fastqc.html', sample=SAMPLE),
        expand('output/raw_fastqc/{sample}.R1_fastqc.html', sample=SAMPLE),
        expand('output/raw_fastqc/{sample}.R2_fastqc.html', sample=SAMPLE)
    output: 'output/multiqc/multiqc.html'
    shell:
        'multiqc -d -n {output} .'

rule build_diamond_database:
    output:
        "output/build_diamond_database/uniprot_ref_proteomes.fasta",
        "output/build_diamond_database/uniprot_ref_proteomes.dmnd",
        "output/build_diamond_database/uniprot_ref_proteomes.taxids"
    threads: 16
    script:
        "scripts/build_diamond_database.py"


rule assembly1:
    input:
        fwd_reads = 'output/quality_trim/{genotype}SC.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{genotype}SC.R2.fastq.gz',
	    merged_reads = 'output/quality_trim/{genotype}SC.merged.fastq.gz'
    output:
        assembly = 'output/assembly1/{genotype}SC.fasta',
        output_dir='output/assembly1/{genotype}SC_spades'
    threads: 8
    resources:
        mem_mb = 50000
    shell:
        "python2 util/spades/bin/spades.py -1 {input.fwd_reads} -2 "
        "{input.rev_reads} -s {input.merged_reads} --threads {threads} "
	    "-o {output.output_dir} && "
        "mv {output.output_dir}/scaffolds.fasta {output.assembly}"

rule length_filter_assembly1:
    input:
        'output/assembly1/{genotype}SC.fasta'
    output:
        'output/length_filter_assembly1/{genotype}SC.fasta'
    shell:
        "bioawk -c fastx '{{ if(length($seq) > 200) {{ print \">\"$name; print "
        "$seq }}}}' {input} > {output}"

rule bowtie2_index_assembly1:
    input:
        'output/length_filter_assembly1/{genotype}SC.fasta'
    output:
        'output/length_filter_assembly1/{genotype}SC.1.bt2'
    params:
        output_prefix = "output/length_filter_assembly1/{genotype}SC"
    shell:
        "bowtie2-build {input} {params.output_prefix}"

rule blast_assembly1:
    input:
        'output/length_filter_assembly1/{genotype}SC.fasta'
    output:
        "output/blast_assembly1/{genotype}SC.tsv"
    threads: 10
    params:
        max_target_seqs = "5",
        evalue = "1e-25",
        max_hsps = "1",
    shell:
        "blastn -db {config[blast_database]} -task megablast -max_target_seqs "
        "{params.max_target_seqs} -max_hsps 1 -evalue {params.evalue} -query "
        "{input} -out {output} -outfmt \"6 qseqid staxids bitscore std\" "
        "-num_threads {threads}"


rule diamond_blast_assembly1:
    input:
        assembly = 'output/length_filter_assembly1/{genotype}SC.fasta',
        db = "output/build_diamond_database/uniprot_ref_proteomes.dmnd",
    output:
        "output/diamond_blast_assembly1/{genotype}SC.out"
    params:
        max_target_seqs = "1",
        evalue = "1e-25"
    threads: 16
    resources:
        mem_mb = 50000
    shell:
        "diamond blastx --query {input.assembly} --max-target-seqs "
        "{params.max_target_seqs} --threads {threads} --sensitive "
        "--db {input.db} --evalue {params.evalue} --outfmt 6 --out {output}"

rule taxify_diamond_blasts1:
    input:
        diamond_hits = "output/diamond_blast_assembly1/{genotype}SC.out",
        taxids = "output/build_diamond_database/uniprot_ref_proteomes.taxids"
    output:
        "output/diamond_blast_assembly1/{genotype}SC.taxified.out",
    params:
        output_prefix = "output/diamond_blast_assembly1/"
    shell:
        "blobtools taxify -f {input.diamond_hits} -m {input.taxids} -s 0 -t 2 "
        "-o {params.output_prefix}"

rule align_to_assembly1:
    input: assembly = match_assembly,
        index = match_assembly_index,
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        merged_reads = 'output/quality_trim/{sample}.merged.fastq.gz'
    output:
        bam = 'output/align_to_assembly1/{sample}.bam',
        bai = 'output/align_to_assembly1/{sample}.bam.bai'
    threads: 12
    resources:
        mem_mb = 20000
    log:
        "output/align_to_assembly1/log/{sample}.log"
    run:
        index_prefix = bowtie2_idx_root(input.index)
        shell("align_and_sort.py -1 {input.fwd_reads} -2 {input.rev_reads} -U "
              "{input.merged_reads} -x " + index_prefix + " -p {threads} > "
              "{output.bam} 2> {log}")
        shell("samtools index {output.bam}")

rule init_blobtools_database1:
    input:
        assembly = "output/length_filter_assembly1/{genotype}SC.fasta",
        blast_hits = "output/blast_assembly1/{genotype}SC.tsv",
        diamond_hits = "output/diamond_blast_assembly1/{genotype}SC.taxified.out",
        bams = get_assembly1_bams_from_genotype
    output:
        "output/init_blobtools_database1/{genotype}.blobDB.json"
        # Also produces .cov files
    resources:
        mem_mb = 20000
    log:
        "output/init_blobtools_database1/log/{genotype}.log"
    run:
        bam_args = ' -b '.join(input.bams)
        output_prefix = os.path.join("output/init_blobtools_database1",
                                     wildcards.genotype)
        shell("blobtools create -i {input.assembly} --type spades --title "
              "{wildcards.genotype} --out " + output_prefix + " --hitsfile "
              "{input.blast_hits} {input.diamond_hits} --nodes "
              "{config[nodes_dmp]} --names {config[names_dmp]} -b "
              + bam_args + " > {log} 2>&1")

# SWITCH TO ASSEMBLY1,2,3 NAMING SCHEME

#rule redundans:
#    input:
#        assembly = 'output/assembly1/{sample}.fasta',
#        fwd_reads = 'output/quality_trim/{sample}.r1.fastq.gz',
#        rev_reads = 'output/quality_trim/{sample}.r2.fastq.gz',
#        merged_reads = 'output/quality_trim/{sample}.merged.fastq.gz'
#    output:
#        'output/redundans/{sample}/scaffolds.filled.fa'
#    params:
#        threads = 10
#    shell:
#        "python2 util/redundans/redundans.py -f {assembly} -i "
#        "{input.fwd_reads} {input.rev_reads} -l {input.merged_reads} "
#        "-r {config[reference_assembly]} -o {output} -t {params.threads}"

# rule create_haplomerger_project:
#     input:
#         'output/assembly1/{sample}.fasta'
#     output:
#         'util/haplomerger2/{sample}'
#     run:
#         if os.path.isdir(output[0]):
#             rmtree(output[0])
#         shell("cp -r util/haplomerger2/template "
#               "util/haplomerger2/{wildcards.sample}")
#
# rule softmask_assembly:
#     input:
#         projdir = 'util/haplomerger2/{sample}',
#         assembly = 'output/assembly1/{sample}.fasta'
#     output:
#         'util/haplomerger2/{sample}/{sample}.fa.gz'
#     script:
#         "scripts/softmask_assembly.py"
#
# rule remove_misjoins:
#     input:
#         "util/haplomerger2/{sample}/{sample}.fa.gz"
#     output:
#         "util/haplomerger2/{sample}/{sample}_A.fa.gz"
#     threads: 10
#     script:
#         "scripts/remove_misjoins.py"
#
# rule haploidify_assembly:
#     input:
#         "util/haplomerger2/{sample}/{sample}_A.fa.gz"
#     output:
#         "util/haplomerger2/{sample}/{sample}_A_ref.fa.gz",
#         "util/haplomerger2/{sample}/{sample}_A_alt.fa.gz"
#     threads: 10
#     script:
#         "scripts/haploidify.py"
