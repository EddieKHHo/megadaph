"""Megadaph Decontamination Pipeline"""
import os
from shutil import (
    move,
    rmtree,
)
from tempfile import NamedTemporaryFile
from uuid import uuid4

from plumbum import (
    FG,
    local,
)
from plumbum.cmd import (
    busco,
    cat,
)

# ==============================================================================
# Set up
# ==============================================================================
# {{{{
configfile: "config.yml"

SAMPLE, PAIR = glob_wildcards(
    os.path.join(config['readsdir'], '{sample}.{pair}.fastq.gz'))

# Remove duplicate entries
SAMPLE = sorted(list(set(SAMPLE)))

# Genotype indices given by first two letters of sample name
GENOTYPE = list(set([x[0:2] for x in SAMPLE]))

GENOTYPE_SAMPLE = {}
for genotype in GENOTYPE:
    GENOTYPE_SAMPLE[genotype] = [x for x in SAMPLE if x.startswith(genotype)]

# Decontamination was done in several iterations, with each iteration consisting
# of:
# 1. Assembly
# 2. Blobplots/Covplots
# 3. Contamination filtering
# Outputs from contamination were reassembled. This was continued until minimal
# contamination was evident in blobplots
ALL_FILTER_ITER = ['1', '2', '3', '_reduced']
DECONTAM_ITER = ['1', '2']

# Variant calling was also done iteratively.
# In the first step, variants with default parameters and high confidence
# variants were called.
# In the second step, this initial variant set was used to estimate
# heterozygosity and variant were re-called.
CALL_ITER = ['_initial']

VARIANT_TYPES = ['snps', 'indels']
# }}}}

# ==============================================================================
# Helper functions
# ==============================================================================
# {{{


def get_iterations_reads(wildcards):
    """Get the current set of reads which have passed filtering"""
    try:
        smp = wildcards.sample
    except AttributeError:
        smp = wildcards.genotype + 'SC'

    outdict = {}
    if wildcards.iter == '_reduced':
        read_dir = os.path.join('output', 'filter_contamination_reduced')
        outdict['fwd_reads'] = os.path.join(read_dir, smp + '.R1.fastq.gz')
        outdict['rev_reads'] = os.path.join(read_dir, smp + '.R2.fastq.gz')
        outdict['unpaired_reads'] = os.path.join(read_dir,
                                                 smp + '.unpaired.fastq.gz')
    elif int(wildcards.iter) == 1:
        read_dir = os.path.join('output', 'quality_trim')
        outdict['fwd_reads'] = os.path.join(read_dir, smp + '.R1.fastq.gz')
        outdict['rev_reads'] = os.path.join(read_dir, smp + '.R2.fastq.gz')
        outdict['unpaired_reads'] = os.path.join(read_dir, smp +
                                                 '.merged.fastq.gz')
    else:
        prev_iter = str(int(wildcards.iter) - 1)
        read_dir = os.path.join('output', 'filter_contamination' + prev_iter)
        outdict['fwd_reads'] = os.path.join(read_dir, smp + '.R1.fastq.gz')
        outdict['rev_reads'] = os.path.join(read_dir, smp + '.R2.fastq.gz')
        outdict['unpaired_reads'] = os.path.join(read_dir, smp +
                                                 '.unpaired.fastq.gz')
    return outdict


def get_assembly_bams_from_genotype(wildcards):
    sample_names = get_samples_for_genotype(wildcards)
    bam_files = [''.join(["output/align_to_assembly", wildcards.iter, "/",
                          x, ".bam"])
                 for x in sample_names]
    return bam_files


def get_assembly_covfiles_from_genotype(wildcards):
    sample_names = get_samples_for_genotype(wildcards)
    cov_files = [''.join(["output/convert_alignment_to_cov", wildcards.iter,
                          "/", x, ".bam.cov"])
                 for x in sample_names]
    return cov_files


def get_filter_alignment(wildcards):
    try:
        smp = wildcards.sample
    except AttributeError:
        smp = wildcards.genotype + 'SC'

    if wildcards.iter == '_reduced':
        bam = ''.join(['output/preliminary_alignment_to_reduced/',
                       smp, '.bam'])
    else:
        bam = ''.join(['output/align_to_assembly', wildcards.iter, '/',
                       smp, '.bam'])
    return bam


def get_samples_for_genotype(wildcards):
    return [x for x in SAMPLE if x.startswith(wildcards.genotype)]


def get_genotype_for_sample(wildcards):
    return ''.join(wildcards.sample[0:2])


def get_starting_control(wildcards):
    """Given a sample ID, return the ID of its starting control"""
    return wildcards.sample[0:2] + "SC"


def match_assembly(wildcards):
    """Given the sample, return the starting control assembly"""
    starting_control = get_starting_control(wildcards)
    assembly = os.path.join("output",
                            "length_filter_assembly" + wildcards.iter,
                            starting_control + ".fasta")
    return assembly


def match_reduced_assembly(wildcards):
    '''Given the sample, return the redundans reduced assembly'''
    starting_control = get_starting_control(wildcards)
    assembly = os.path.join("output",
                            "length_filter_assembly_reduced",
                            starting_control + ".fasta")
    return assembly


def match_assembly_index(wildcards):
    """Given the sample, return the starting control assembly bowtie2 index"""
    starting_control = get_starting_control(wildcards)
    return os.path.join("output",
                        "length_filter_assembly" + wildcards.iter,
                        starting_control + ".1.bt2")


def match_reduced_assembly_index(wildcards):
    """Given the sample, return the redundans reduced ssembly bowtie2 index"""
    starting_control = get_starting_control(wildcards)
    index = os.path.join("output",
                         "length_filter_assembly_reduced",
                         starting_control + ".1.bt2")
    return index


def get_bowtie2_idx_root(index):
    """Given the path to a forward bowtie2 index, return its root name"""
    return os.path.splitext(os.path.splitext(index)[0])[0]


def get_exclusions(wildcards):
    '''Get the list of exclusions for a decontamination iteration'''
    if wildcards.iter == '_reduced':
        exclusions = ''.join(['output/filter_mitochondrial_scaffolds/',
                              wildcards.genotype, 'SC.txt'])
    else:
        exclusions = ''.join(['output/find_contam_contigs', wildcards.iter,
                              '/', wildcards.genotype, '.txt'])
    return exclusions


def build_filter_expression(param):
    filter_expression = ' || '.join([key + ' ' + value for key, value in param])
    return filter_expression
# }}}

# ==============================================================================
# Targets
# ==============================================================================
# {{{
rule all:
    input:
        'output/multiqc/multiqc.html',
        expand("output/produce_blobplots{iter}/{genotype}/family/{genotype}."
               "bestsum.family.p20.span.100.blobplot.cov0.png",
               genotype=GENOTYPE, iter=ALL_FILTER_ITER),
        expand("output/produce_covplots{iter}/{sample}.covsum.png",
               sample=SAMPLE, iter=ALL_FILTER_ITER),
        expand("output/find_contam_contigs{iter}/{genotype}.txt",
               iter=DECONTAM_ITER, genotype=GENOTYPE),
        expand('output/blast_against_mitochondria/{genotype}.tsv',
               genotype=GENOTYPE),
        expand('output/extract_variant_quality_scores{iter}/{sample}.{type}.table',
               iter=CALL_ITER, sample=SAMPLE, type=VARIANT_TYPES),
        expand('output/plot_variant_quality_scores{iter}/{sample}.svg',
               sample=SAMPLE, iter=CALL_ITER)
        # }}}

# ==============================================================================
# Build extra input files
# ==============================================================================
# {{{
rule build_diamond_database:
    output:
        "output/build_diamond_database/uniprot_ref_proteomes.fasta",
        "output/build_diamond_database/uniprot_ref_proteomes.dmnd",
        "output/build_diamond_database/uniprot_ref_proteomes.taxids"
    threads: 16
    script:
        "scripts/build_diamond_database.py"
# }}}

# ==============================================================================
# Quality Control / Trimming
# ==============================================================================
# {{{

rule trim_adapters:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        fwd_reads = temp('output/trim_adapters/{sample}.R1.fastq.gz'),
        rev_reads = temp('output/trim_adapters/{sample}.R2.fastq.gz')
    log: "output/trim_adapters/log/{sample}.log"
    threads: 10
    params:
        ref = config['adapters'],
        k = '23',
        ktrim = 'r',
        mink = '4',
        hdist = '1'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.fwd_reads} out2={output.rev_reads} ref={params.ref} "
        "k={params.k} ktrim={params.ktrim} mink={params.mink} "
        "hdist={params.hdist} threads={threads} tpe tbo 2> {log}"


rule merge_reads:
    input:
        fwd_reads = rules.trim_adapters.output.fwd_reads,
        rev_reads = rules.trim_adapters.output.rev_reads
    output:
        fwd_reads = 'output/merge_reads/{sample}.R1.fastq.gz',
        rev_reads = 'output/merge_reads/{sample}.R2.fastq.gz',
        merged_reads = 'output/merge_reads/{sample}.merged.fastq.gz',
        insert_hist = 'output/merge_reads/{sample}.hist'
    log: "output/merge_reads/log/{sample}.log"
    params:
        vstrict = 't'
    shell:
        "bbmerge.sh in1={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.merged_reads} outu={output.fwd_reads} "
        "outu2={output.rev_reads} ihist={output.insert_hist} "
        "vstrict={params.vstrict} 2> {log}"


rule quality_trim:
    input:
        fwd_reads = rules.merge_reads.output.fwd_reads,
        rev_reads = rules.merge_reads.output.rev_reads,
        merged_reads = rules.merge_reads.output.merged_reads
    output:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        merged_reads = 'output/quality_trim/{sample}.merged.fastq.gz'
    log:
        paired = "output/quality_trim/log/{sample}.paired.log",
        unpaired = "output/quality_trim/log/{sample}.unpaired.log"
    threads: 10
    params:
        qtrim = 'rl',
        trimq = '20',
        minlen = '50'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} "
        "out={output.fwd_reads} out2={output.rev_reads} threads={threads} "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "2> {log.paired} &&"
        "bbduk.sh in={input.merged_reads} out={output.merged_reads} "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "threads={threads} 2> {log.unpaired}"
# }}}

# ==============================================================================
# Assembly-Decontamination Iterations
# ==============================================================================
# {{{

rule assembly:
    input:
        unpack(get_iterations_reads)
    output:
        assembly = 'output/assembly{iter}/{genotype}SC.fasta',
        output_dir = 'output/assembly{iter}/{genotype}SC_spades'
    threads: 8
    resources:
        mem_mb = 150000
    shell:
        "python2 util/spades/bin/spades.py -1 {input.fwd_reads} -2 "
        "{input.rev_reads} -s {input.unpaired_reads} --threads {threads} "
        "-o {output.output_dir} && "
        "mv {output.output_dir}/scaffolds.fasta {output.assembly}"

rule length_filter_assembly:
    input:
        lambda wildcards: (
            ''.join(['output/filter_mitochondrial_scaffolds/',
                     wildcards.genotype, 'SC.fasta'])
            if wildcards.iter == '_reduced' else
            ''.join(['output/assembly', wildcards.iter, '/', wildcards.genotype,
                     'SC.fasta'])
        )
    output:
        'output/length_filter_assembly{iter}/{genotype}SC.fasta'
    params:
        minlen = lambda wildcards: (
            "1000" if wildcards.iter == "_reduced" else "200")
    shell: "length_filter_fasta.pl {params.minlen} {input} > {output}"

rule index_length_filtered_assembly:
    input:
        'output/length_filter_assembly{iter}/{genotype}SC.fasta'
    output:
        bt2 = 'output/length_filter_assembly{iter}/{genotype}SC.1.bt2',
        fai = 'output/length_filter_assembly{iter}/{genotype}SC.fasta.fai',
        picard = 'output/length_filter_assembly{iter}/{genotype}SC.dict'
    params:
        output_prefix = 'output/length_filter_assembly{iter}/{genotype}SC'
    shell:
        'bowtie2-build {input} {params.output_prefix} & '
        'samtools faidx {input} & '
        'picard CreateSequenceDictionary R={input} O={output.picard}'

rule blast_assembly:
    input:
        'output/length_filter_assembly{iter}/{genotype}SC.fasta'
    output:
        "output/blast_assembly{iter}/{genotype}SC.tsv"
    threads: 10
    params:
        max_target_seqs = "5",
        evalue = "1e-25",
        max_hsps = "1",
    shell:
        "blastn -db {config[blast_database]} -task megablast -max_target_seqs "
        "{params.max_target_seqs} -max_hsps 1 -evalue {params.evalue} -query "
        "{input} -out {output} -outfmt \"6 qseqid staxids bitscore std\" "
        "-num_threads {threads}"

rule diamond_blast_assembly:
    input:
        assembly = 'output/length_filter_assembly{iter}/{genotype}SC.fasta',
        db = "output/build_diamond_database/uniprot_ref_proteomes.dmnd",
    output:
        "output/diamond_blast_assembly{iter}/{genotype}SC.out"
    params:
        max_target_seqs = "1",
        evalue = "1e-25"
    threads: 16
    resources:
        mem_mb = 50000
    shell:
        "diamond blastx --query {input.assembly} --max-target-seqs "
        "{params.max_target_seqs} --threads {threads} --sensitive "
        "--db {input.db} --evalue {params.evalue} --outfmt 6 --out {output}"

rule taxify_diamond_blasts:
    input:
        diamond_hits = "output/diamond_blast_assembly{iter}/{genotype}SC.out",
        taxids = "output/build_diamond_database/uniprot_ref_proteomes.taxids"
    output:
        "output/diamond_blast_assembly{iter}/{genotype}SC.taxified.out",
    params:
        output_prefix = "output/diamond_blast_assembly{iter}/"
    shell:
        "blobtools taxify -f {input.diamond_hits} -m {input.taxids} -s 0 -t 2 "
        "-o {params.output_prefix}"

rule align_to_assembly:
    input:
        unpack(get_iterations_reads),
        assembly = match_assembly,
        index = match_assembly_index
    output:
        bam = 'output/align_to_assembly{iter}/{sample}.bam',
        bai = 'output/align_to_assembly{iter}/{sample}.bam.bai'
    threads: 12
    resources:
        mem_mb = 20000
    params:
        max_insert = 1000
    log:
        "output/align_to_assembly{iter}/log/{sample}.log"
    run:
        index_prefix = get_bowtie2_idx_root(input.index)
        shell('bowtie2 -1 {input.fwd_reads} -2 {input.rev_reads} '
              '-U {input.unpaired_reads} -X {params.max_insert} '
              '-x ' + index_prefix + ' --rg-id={wildcards.sample} '
              '--rg=LIB:{wildcards.sample} --rg=PL:illumina '
              '--rg=SM:{wildcards.sample} -p {threads} | samtools view -bh - | '
              'samtools sort - > {output.bam} 2> {log}')
        shell('samtools index {output.bam}')

rule convert_alignment_to_cov:
    input:
        bam = "output/align_to_assembly{iter}/{sample}.bam",
        assembly = lambda wildcards: ''.join([
            "output/length_filter_assembly", wildcards.iter, '/',
            get_genotype_for_sample(wildcards), 'SC.fasta'])
    output:
        "output/convert_alignment_to_cov{iter}/{sample}.bam.cov"
    resources:
        mem_mb = 20000
    params:
        output_prefix = "output/convert_alignment_to_cov{iter}/"
    log:
        "output/convert_alignment_to_cov{iter}/logs/{sample}.log"
    shell:
        "blobtools map2cov -i {input.assembly} -b {input.bam} "
        "-o {params.output_prefix} 2> {log}"

rule init_blobtools_database:
    input:
        assembly = "output/length_filter_assembly{iter}/{genotype}SC.fasta",
        blast_hits = "output/blast_assembly{iter}/{genotype}SC.tsv",
        diamond_hits = ('output/diamond_blast_assembly{iter}/{genotype}SC.'
                        'taxified.out'),
        covs = get_assembly_covfiles_from_genotype
    output:
        "output/init_blobtools_database{iter}/{genotype}.blobDB.json"
    resources:
        mem_mb = 20000
    params:
        output_prefix = "output/init_blobtools_database{iter}/{genotype}"
    log:
        "output/init_blobtools_database{iter}/log/{genotype}.log"
    run:
        cov_args = ' -c '.join(input.covs)
        shell("blobtools create -i {input.assembly} "
              "--title {wildcards.genotype} --out {params.output_prefix} "
              "--hitsfile {input.blast_hits} --hitsfile {input.diamond_hits} "
              "--nodes {config[nodes_dmp]} --names {config[names_dmp]} "
              "-c " + cov_args + " > {log} 2>&1")

rule produce_blobplots:
    input:
        "output/init_blobtools_database{iter}/{genotype}.blobDB.json"
    output:
        ('output/produce_blobplots{iter}/{genotype}/family/{genotype}.bestsum.'
         'family.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/genus/{genotype}.bestsum.'
         'genus.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/order/{genotype}.bestsum.'
         'order.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/phylum/{genotype}.bestsum.'
         'phylum.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/species/{genotype}.bestsum.'
         'species.p20.span.100.blobplot.cov0.png')
    threads: 5
    resources:
        mem_mb = 40000
    params:
        output_prefix = "output/produce_blobplots{iter}/{genotype}"
    shell:
        "scripts/produce_blobplots.py -o {params.output_prefix} -d {input}"

rule produce_covplots:
    input:
        cov = "output/convert_alignment_to_cov{iter}/{sample}.bam.cov",
        db = lambda wildcards: ''.join(["output/init_blobtools_database",
                                        wildcards.iter, "/",
                                        get_genotype_for_sample(wildcards),
                                        ".blobDB.json"])
    output:
        "output/produce_covplots{iter}/{sample}.covsum.png"
    params:
        output_prefix = "output/produce_covplots{iter}/{sample}",
        rank = "superkingdom"
    run:
        shell("blobtools covplot -p 20 -c {input.cov} "
              "-i {input.db} -r {params.rank} "
              "-o {params.output_prefix}")

        outdir = local.path(params.output_prefix).dirname
        output_files = outdir.glob(wildcards.sample + "*")
        for f in output_files:
            extensions = '.'.join(f.name.split(".")[-2:])
            newname = outdir / (wildcards.sample + "." + extensions)
            f.move(newname)

rule produce_blobtable:
    input:
        db = "output/init_blobtools_database{iter}/{genotype}.blobDB.json"
    output:
        "output/produce_blobtable{iter}/{genotype}.blobDB.bestsum.table.txt"
    shell:
        "blobtools view -r all -b -i {input.db} "
        "-o output/produce_blobtable{wildcards.iter}/"


# List the contigs which failed the filtering step
rule find_contam_contigs:
    input:
        "output/produce_blobtable{iter}/{genotype}.blobDB.bestsum.table.txt"
    output:
        "output/find_contam_contigs{iter}/{genotype}.txt"
    params:
        find_contam_contigs = 'scripts/find_contam_contigs{iter}.R'
    shell:
        '{params.find_contam_contigs} {input} > {output}'


# rule add_mitochondrial_contigs_to_exclusions:
#     input:
#         mito = 'output/find_mitochondrial_contigs/{genotype}.txt',
#         other_contam = 'output/find_contam_contigs2/{genotype}.txt'
#     output:
#         'output/find_contam_contigs2/{genotype}_with_mitochondrial.txt'
#     shell:
#         'cat {input.mito} {input.other_contam} > {output}'


# List the contigs which passed the filtering step
rule generate_inclusion_list:
    input:
        exclusions = get_exclusions,
        assembly = get_filter_alignment
    output:
        "output/generate_inclusion_list{iter}/{genotype}.txt"
    shell:
        "list_csomes {input.assembly} | complement.sh /dev/stdin "
        "{input.exclusions} > {output}"


rule filter_contamination:
    input:
        passing_contigs = lambda wildcards: ''.join([
            "output/generate_inclusion_list", wildcards.iter, "/",
            get_genotype_for_sample(wildcards), ".txt"]),
        bam = get_filter_alignment
    output:
        fwd = "output/filter_contamination{iter}/{sample}.R1.fastq.gz",
        rev = "output/filter_contamination{iter}/{sample}.R2.fastq.gz",
        unpaired = "output/filter_contamination{iter}/{sample}.unpaired.fastq.gz"
    threads: 16
    resources:
        mem_mb = 60000
    params:
        output_prefix = "output/filter_contamination{iter}/{sample}"
    log:
        "output/filter_contamination{iter}/logs/{sample}.log"
    run:
        # This step removes all reads which are not mapped to a contig in the
        # inclusion list (this includes unmapped reads).
        shell("extract_csomes.py -n 200 -p {threads} -o {params.output_prefix} "
              "-i {input.passing_contigs} -f fastq {input.bam} 2> {log}")

        outdir = local.path(output.unpaired).dirname
        tmp = outdir / (uuid4().hex + '.fastq.gz')
        # Remove all unpaired reads which are not merged
        shell("zcat {output.unpaired} | paste - - - - | awk "
              "'length($2) >= 151' | sed 's/\\t/\\n/g' | gzip - > " + str(tmp))
        move(str(tmp), output.unpaired)

# }}}

# ==============================================================================
# Reduction/Scaffolding
# ==============================================================================
# {{{

rule redundans:
    input:
        fwd_reads = 'output/filter_contamination2/{genotype}SC.R1.fastq.gz',
        rev_reads = 'output/filter_contamination2/{genotype}SC.R2.fastq.gz',
        assembly = 'output/assembly3/{genotype}SC.fasta'
    output:
        fasta = 'output/redundans/{genotype}SC.fasta',
        index = 'output/redundans/{genotype}SC.1.bt2'
    params:
        outdir = 'output/redundans/{genotype}'
    threads: 16
    resources:
        mem_mb = 200000
    log:
        'output/redundans/log/{genotype}.log'
    run:
        shell('rm -rf {params.outdir}')
        shell('python2 {config[redundans_bin]} -v -f {input.assembly} '
              '-i {input.fwd_reads} {input.rev_reads} -o {params.outdir} '
              '-r {config[nuclear_reference]} --norearrangements -t {threads} '
              '2> {log}')
        shell('mv {params.outdir}/scaffolds.reduced.fa {output.fasta}')
        shell('samtools faidx {output.fasta}')
        index_prefix = os.path.splitext(output.fasta)[0]
        shell('bowtie2-build {output.fasta} ' + index_prefix)

rule blast_against_mitochondria:
    input:
        'output/redundans/{genotype}SC.fasta'
    output:
        list = 'output/blast_against_mitochondria/{genotype}.txt',
        blast = 'output/blast_against_mitochondria/{genotype}.tsv'
    run:
        # BLAST assembly vs. mtdna
        shell('blastn -subject {input} '
              '-query {config[mitochondrial_reference]} '
              '-num_alignments 10 -outfmt 6 > {output.blast}')
        # Get the contig names
        shell('cat {output.blast} | cut -f 2 | uniq -d > {output.list}')

rule filter_mitochondrial_scaffolds:
    input:
        blast = 'output/blast_against_mitochondria/{genotype}.tsv',
        assembly = 'output/redundans/{genotype}SC.fasta'
    output:
        fasta = 'output/filter_mitochondrial_scaffolds/{genotype}SC.fasta',
        txt = 'output/filter_mitochondrial_scaffolds/{genotype}SC.txt'
    shell:
        'scripts/filter_mitochondrial_scaffolds.py --blast {input.blast} '
        '--assembly {input.assembly} --outfasta {output.fasta} '
        '--outtxt {output.txt}'

rule preliminary_alignment_to_reduced:
    input:
        fwd_reads = 'output/filter_contamination2/{sample}.R1.fastq.gz',
        rev_reads = 'output/filter_contamination2/{sample}.R2.fastq.gz',
        unpaired_reads = (
            'output/filter_contamination2/{sample}.unpaired.fastq.gz'),
        assembly = lambda wildcards: (
            'output/redundans/' + wildcards.sample[0:2] + 'SC.fasta'),
        index = lambda wildcards: (
            'output/redundans/' + wildcards.sample[0:2] + 'SC.1.bt2')
    output:
        bam = 'output/preliminary_alignment_to_reduced/{sample}.bam',
        bai = 'output/preliminary_alignment_to_reduced/{sample}.bam.bai'
    threads: 12
    resources:
        mem_mb = 20000
    params:
        max_insert = 1000
    log:
        "output/preliminary_alignment_to_reduced/log/{sample}.log"
    run:
        index_prefix = get_bowtie2_idx_root(input.index)
        shell('bowtie2 -1 {input.fwd_reads} -2 {input.rev_reads} '
              '-U {input.unpaired_reads} -X {params.max_insert} '
              '-x ' + index_prefix + ' --rg-id={wildcards.sample} '
              '--rg=LIB:{wildcards.sample} --rg=PL:illumina '
              '--rg=SM:{wildcards.sample} -p {threads} | samtools view -bh - | '
              'samtools sort - > {output.bam} 2> {log}')
        shell('samtools index {output.bam}')

rule index_reduced_assembly:
    input:
        'output/filter_mitochondrial_scaffolds/{genotype}SC.fasta'
    output:
        bt2 = 'output/filter_mitochondrial_scaffolds/{genotype}SC.1.bt2',
        picard = 'output/filter_mitochondrial_scaffolds/{genotype}SC.dict',
        fai = 'output/filter_mitochondrial_scaffolds/{genotype}SC.fasta.fai'
    params:
        output_prefix = "output/filter_mitochondrial_scaffolds/{genotype}SC"
    shell:
        "bowtie2-build {input} {params.output_prefix} && "
        "samtools faidx {input} && "
        "picard CreateSequenceDictionary R={input} O={output.picard}"

# }}}

# ==============================================================================
# Variant Calling Pre-Processing
# ==============================================================================
# {{{

rule mark_duplicates:
    input:
        bam = 'output/align_to_assembly_reduced/{sample}.bam',
        bai = 'output/align_to_assembly_reduced/{sample}.bam.bai'
    output:
        bam = 'output/mark_duplicates/{sample}.bam',
        bai = 'output/mark_duplicates/{sample}.bam.bai'
    resources:
        mem_mb = 30000
    log:
        'output/mark_duplicates/log/{sample}.log'
    shell:
        'picard MarkDuplicates I={input.bam} O={output.bam} '
        'REMOVE_DUPLICATES=True M={log} && '
        'samtools index {output.bam}'

# rule recalibrate_base_quality:
#     input:
#         bam = 'output/mark_duplicates/{sample}.bam',
#         bai = 'output/mark_duplicates/{sample}.bam.bai',
#         assembly = match_reduced_assembly
#     output:
#         table = 'output/recalibrate_base_quality/{sample}.table',
#         bam = 'output/recalibrate_base_quality/{sample}.bam',
#         bai = 'output/recalibrate_base_quality/{sample}.bam.bai'
#     threads: 8
#     resources:
#         mem_mb = 20000
#     log:
#         'output/recalibrate_base_quality/log/{sample}.log'
#     shell:
#         'gatk -T BaseRecalibrator -nct {threads} -o {output.table} '
#         '-R {input.assembly} -I {input.bam} 2> {log} && '
#         'gatk -T PrintReads -R {input.assembly} -I {input.bam} '
#         '-BQSR {output.table} && samtools index {output.bam}'

# }}}

# ==============================================================================
# Variant Calling
# ==============================================================================
# {{{
rule call_variants:
    input:
        bam = 'output/mark_duplicates/{sample}.bam',
        bai = 'output/mark_duplicates/{sample}.bam.bai',
        assembly = match_reduced_assembly,
        index = match_reduced_assembly_index
    output:
        gvcf = 'output/call_variants{iter}/{sample}.g.vcf'
    resources:
        mem_mb = 20000
    params:
        snp_heterozygosity = 0.015,
        indel_heterozygosity = 0.01
    log:
        'output/call_variants{iter}/log/{sample}.log'
    shell:
        'gatk HaplotypeCaller '
        '-R {input.assembly} '
        '-I {input.bam} '
        '--emit-ref-confidence GVCF '
        '-O {output} '
        '--heterozygosity {params.snp_heterozygosity} '
        '--indel-heterozygosity {params.indel_heterozygosity} '

rule genotype_gvcfs:
    input:
        gvcf = 'output/call_variants{iter}/{sample}.g.vcf',
        ref = match_reduced_assembly,
        index = match_reduced_assembly_index
    output:
        'output/genotype_gvcfs{iter}/{sample}.vcf'
    params:
        snp_heterozygosity = 0.015,
        indel_heterozygosity = 0.01
    shell:
        'gatk GenotypeGVCFs '
        '-R {input.ref} '
        '-V {input.gvcf} '
        '-O {output} '
        '--heterozygosity {params.snp_heterozygosity} '
        '--indel-heterozygosity {params.indel_heterozygosity} '


rule select_snps:
    input:
        vcf = 'output/genotype_gvcfs{iter}/{sample}.vcf'
        ref = match_reduced_assembly,
        index = match_reduced_assembly_index
    output:
        'output/select_variants{iter}/{sample}.snps.vcf'
    shell:
        'gatk SelectVariants '
        '-R {input.ref} '
        '-V {input.vcf} '
        '-selectType SNP '
        '-o {output}'


rule select_indels:
    input:
        vcf = 'output/genotype_gvcfs{iter}/{sample}.vcf'
        ref = match_reduced_assembly,
        index = match_reduced_assembly_index
    output:
        'output/select_variants{iter}/{sample}.indels.vcf'
    shell:
        'gatk SelectVariants '
        '-R {input.ref} '
        '-V {input.vcf} '
        '-selectType INDEL '
        '-O {output}'

rule extract_variant_quality_scores:
    input:
        vcf = 'output/select_variants{iter}/{sample}.{type}.vcf',
        ref = match_reduced_assembly,
        index = match_reduced_assembly_index
    output:
        'output/extract_variant_quality_scores{iter}/{sample}.{type}.table'
    shell:
        'gatk VariantsToTable '
        '-R {input.ref} '
        '-V {input.vcf} '
        '-F CHROM -F QUAL -F QD -F DP -F MQ -F MQRankSum -F FS '
        '-F ReadPosRankSum -F SOR '
        '--allowMissingData '
        '-O {output}'


rule plot_variant_quality_scores:
    input:
        snps = 'output/extract_variant_quality_scores{iter}/{sample}.snps.vcf',
        indels = (
            'output/extract_variant_quality_scores{iter}/{sample}.indels.vcf')
    output:
        'output/plot_variant_quality_scores{iter}/{sample}.svg'
    script:
        'scripts/plot_variant_quality_scores.R'


# rule filter_snps:
#     input:
#         vcf = 'output/select_variants{iter}/{sample}.snps.vcf',
#         ref = match_reduced_assembly,
#         index = match_reduced_assembly_index
#     output:
#         'output/filter_variants{iter}/{sample}.snps.vcf'
#     params:
#         QD = '< 2.0',
#         FS = '> 60.0',
#         MQ = '< 40.0',
#         MQRankSum = '< -12.5',
#         ReadPosRankSum = '< -8.0'
#     run:
#         filter_expression = build_filter_expression(params)
#         'gatk VariantFiltration '
#         '-R {input.ref} '
#         '-V {input.vcf} '
#         '-O {output} '
#         '--filterName snp_filter '
#         '--filterExpression ' + filter_expression
#
# rule filter_indels:
#     input:
#         vcf = 'output/select_variants{iter}/{sample}.indels.vcf',
#         ref = match_reduced_assembly,
#         index = match_reduced_assembly_index
#     output:
#         'output/filter_variants{iter}/{sample}.indels.vcf'
#     params:
#         QD = '< 2.0',
#         FS = '> 200.0',
#         ReadPosRankSum = '< -20.0'
#     run:
#         filter_expression = build_filter_expression(params)
#         'gatk VariantFiltration '
#         '-R {input.ref} '
#         '-V {input.vcf} '
#         '-O {output} '
#         '--filterName indel_filter '
#         '--filterExpression ' + filter_expression

>>>>>>> Added snp/indel extraction + filtering
# }}}

# ==============================================================================
# Summarize Pipeline
# ==============================================================================
# {{{

rule raw_fastqc:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        'output/raw_fastqc/{sample}.R1_fastqc.html',
        'output/raw_fastqc/{sample}.R2_fastqc.html',
    params:
        outdir = 'output/raw_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads}"

rule clean_fastqc:
    input:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        unpaired_reads = 'output/quality_trim/{sample}.merged.fastq.gz'
    output:
        'output/clean_fastqc/{sample}.R1_fastqc.html',
        'output/clean_fastqc/{sample}.R2_fastqc.html',
        'output/clean_fastqc/{sample}.merged_fastqc.html'
    params:
        outdir = 'output/clean_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads} "
        "{input.merged_reads}"

rule quast:
    input:
        unpack(get_iterations_reads),
        assembly = 'output/length_filter_assembly{iter}/{genotype}SC.fasta',
    output:
        'output/quast{iter}/{genotype}/report.html'
    threads: 6
    params:
        outdir = "output/quast{iter}/{genotype}"
    resources:
        mem_mb = 40000
    shell:
        "quast.py -o {params.outdir} --eukaryote -1 {input.fwd_reads} "
        "-2 {input.rev_reads} -t {threads} --no-snps {input.assembly}"

rule busco:
    input: 'output/length_filter_assembly{iter}/{genotype}SC.fasta'
    output: 'output/busco{iter}/{genotype}/short_summary_{genotype}.txt'
    threads: 8
    params:
        outdir = 'output/busco{iter}/{genotype}'
    run:
        outdir = local.path(params.outdir)
        outdir.delete()
        outdir.mkdir()
        outdir_root = outdir.dirname
        local.env['BUSCO_CONFIG_FILE'] = local.path(config['busco_config'])
        local.env['AUGUSTUS_CONFIG_PATH'] = local.path(
            config['augustus_config'])
        local.env['PATH'] = ':'.join([
            local.path(config['augustus_scripts']), local.env['PATH']
        ])
        assembly = local.path(input)
        lineage_file = local.path(config['busco_database'])
        tmp_outdir = outdir_root / ('run_' + wildcards.genotype)

        with local.cwd(outdir_root):
            busco['-i', assembly, '-o', wildcards.genotype, '-l', lineage_file,
            '-m', 'geno', '-f', '--cpu', threads, '-e', params.evalue] & FG

            for f in tmp_outdir.list():
                f.move(outdir)

            tmp_outdir.delete()

rule multiqc:
    input:
        expand('output/raw_fastqc/{sample}.R1_fastqc.html', sample=SAMPLE),
        expand('output/raw_fastqc/{sample}.R2_fastqc.html', sample=SAMPLE),
        expand('output/clean_fastqc/{sample}.R1_fastqc.html', sample=SAMPLE),
        expand('output/clean_fastqc/{sample}.R2_fastqc.html', sample=SAMPLE),
        expand('output/clean_fastqc/{sample}.merged_fastqc.html',
               sample=SAMPLE),
        expand('output/quast{iter}/{genotype}/report.html',
               iter=ALL_FILTER_ITER, genotype=GENOTYPE),
        expand('output/busco{iter}/{genotype}/short_summary_{genotype}.txt',
               iter=ALL_FILTER_ITER, genotype=GENOTYPE),
        expand('output/mark_duplicates/{sample}.bam', sample=SAMPLE)
    output: 'output/multiqc/multiqc.html'
    shell:
        'multiqc -f -d -n {output} .'
# }}}
