"""Megadaph Variant Calling Pipeline"""

import os
from tempfile import NamedTemporaryFile
from uuid import uuid4

from fmbiopy.fmlist import flatten
import numpy as np
from plumbum import (
    FG,
    local,
)
from plumbum.cmd import (
    blobtools,
    busco,
    cat,
)
import scipy.stats as st

# ==============================================================================
# Set up
# ==============================================================================
# {{{{
configfile: "config.yml"

SAMPLE, PAIR = glob_wildcards(
    os.path.join(config['readsdir'], '{sample}.{pair}.fastq.gz'))

# Remove duplicate entries
SAMPLE = sorted(list(set(SAMPLE)))

# SAMPLE = [x for x in SAMPLE if "FA" not in x]
# SAMPLE = [x for x in SAMPLE if "GB" not in x]
# SAMPLE = [x for x in SAMPLE if "GC" not in x]
# SAMPLE = [x for x in SAMPLE if "IA" not in x]
# SAMPLE = [x for x in SAMPLE if "IC" not in x]

# Genotype indices given by first two letters of sample name
GENOTYPE = list(set([x[0:2] for x in SAMPLE]))

GENOTYPE_TO_SAMPLE = {}
for genotype in GENOTYPE:
    GENOTYPE_TO_SAMPLE[genotype] = [x for x in SAMPLE if x.startswith(genotype)]

# Decontamination was done in several iterations, with each iteration consisting
# of:
# 1. Assembly
# 2. Blobplots/Covplots
# 3. Contamination filtering
# Outputs from contamination were reassembled. This was continued until minimal
# contamination was evident in blobplots
PLOT_ITER = ['1', '2', '_unmasked']
DECONTAM_ITER = ['1', '2', '_reduced']
ASSEMBLY_ITER = ['1', '2', '3']


# Variant calling was also done iteratively.
# In the first step, variants with default parameters and high confidence
# variants were called.
# In the second step, this initial variant set was used to estimate
# heterozygosity and variant were re-called.
CALL_ITER = ['_initial']

VARIANT_TYPES = ['snps', 'indels', 'other']

# Suffixes for various types of fasta indices
FASTA_INDICES = {
    'bowtie2': ['.1.bt2', '.2.bt2', '.3.bt2', '.4.bt2', '.rev.1.bt2',
                '.rev.2.bt2'],
    'picard': ['.dict'],
    'samtools': ['.fasta.fai'],
    'bwa': ['.fasta.amb', '.fasta.ann', '.fasta.bwt', '.fasta.pac', '.fasta.sa']
}
INDEX_SUFFIXES = flatten(FASTA_INDICES.values())
# }}}}

# ==============================================================================
# Helper functions
# ==============================================================================
# {{{

def match_reads(wildcards):
    """Match reads to the current wildcards."""
    try:
        smp = wildcards.sample
    except AttributeError:
        smp = wildcards.genotype + 'SC'
    outdict = {}
    read_dir = local.path('output')
    if wildcards.iter in ['_unmasked', '_masked', '_ref']:
        read_dir = read_dir / 'filter_contamination_reduced'
    elif wildcards.iter == '_reduced':
        read_dir = read_dir / 'filter_contamination2'
    elif int(wildcards.iter) == 1:
        read_dir = read_dir / 'quality_trim'
    else:
        prev_iter = str(int(wildcards.iter) - 1)
        read_dir = read_dir / ('filter_contamination' + prev_iter)
    outdict['fwd_reads'] = str(read_dir / (smp + '.R1.fastq.gz'))
    outdict['rev_reads'] = str(read_dir / (smp + '.R2.fastq.gz'))
    outdict['unpaired_reads'] = str(read_dir / (smp + '.unpaired.fastq.gz'))
    return outdict


def get_sample(wildcards):
    """Get the sample from the wildcards.

    Return the starting control if wildcards.sample doesn't exist.
    """
    try:
        return wildcards.sample
    except AttributeError:
        return wildcards.genotype + 'SC'


def match_filter_alignment(wildcards):
    """Get an alignment which is targeted for contamination filtering."""
    smp = get_sample(wildcards)
    outdict = dict()
    if wildcards.iter in ['_reduced', '_masked', '_unmasked']:
        dir = local.path('output') / 'align_to_assembly_reduced'
    else:
        dir = local.path('output') / ('align_to_assembly' + wildcards.iter)
    outdict['bam'] = str(dir / (smp + '.bam'))
    outdict['bai'] = str(dir / (smp + '.bam.bai'))
    return outdict


def get_genotype(wildcards):
    """Get the genotype from the wildcards."""
    try:
        return wildcards.genotype
    except AttributeError:
        return ''.join(wildcards.sample[0:2])


def get_starting_control(wildcards):
    """Get the starting control from the wildcards."""
    return get_genotype(wildcards) + 'SC'


def match_assembly(wildcards):
    """Match the current assembly and indices to the wildcards."""
    outdict = dict()
    if hasattr(wildcards, 'iter'):
        if wildcards.iter == '_ref':
            outdict['assembly'] = config['nuclear_reference']
            prefix = os.path.splitext(outdict['assembly'])[0]
            dir = local.path(outdict['assembly']).dirname
            outdict['indices'] = [
                str(dir / (prefix + suffix)) for suffix in INDEX_SUFFIXES]
            return outdict

    starting_control = get_starting_control(wildcards)
    if hasattr(wildcards, 'call') or hasattr(wildcards, 'vartype'):
        dir = local.path('output') / ('repeatmasker')
    elif wildcards.iter in ['_masked', '_unmasked']:
        dir = local.path('output') / 'length_filter_assembly_reduced'
    else:
        dir = local.path('output') / ('length_filter_assembly' + wildcards.iter)
    outdict['assembly'] = str(dir / (starting_control + '.fasta'))
    outdict['indices'] = [str(dir / (starting_control + suffix)) for suffix in
                          INDEX_SUFFIXES]
    return outdict


def build_filter_expression(parameters):
    """Given a set of filter conditions, build a GATK filter expression."""
    param_list = []
    for key, value in parameters.items():
        if not isinstance(parameters[key], str):
            for item in parameters[key]:
                param_list.append(' '.join([key, item]))
        else:
            param_list.append(' '.join([key, value]))
    filter_expression = '"' + ' || '.join(param_list) + '"'
    return filter_expression


def clear_directory(dir):
    """Delete the contents of a directory."""
    dir = local.path(dir)
    dir.delete()
    dir.mkdir()

# }}}

# ==============================================================================
# Targets
# ==============================================================================
# {{{
rule all:
    input:
        'output/multiqc/multiqc.html',
        expand("output/produce_blobplots{iter}/{genotype}/family/{genotype}."
               "bestsum.family.p20.span.100.blobplot.cov0.png",
               genotype=GENOTYPE, iter=PLOT_ITER),
        expand("output/produce_covplots{iter}/{sample}.covsum.png",
               sample=SAMPLE, iter=PLOT_ITER),
        expand('output/plot_variant_quality_scores{call}/{sample}.svg',
               sample=SAMPLE, call=CALL_ITER),
        expand('output/calc_number_filtered_sites{call}/{sample}.{type}.txt',
               call=CALL_ITER, sample=SAMPLE, type=VARIANT_TYPES),
        expand('output/select_unique_variants{call}/{sample}.{type}.table',
               sample=SAMPLE, call=CALL_ITER, type=VARIANT_TYPES)
        # }}}


# ==============================================================================
# Utility Rules
# ==============================================================================
# {{{
rule index_bam:
    input:
        'output/{dir}/{group}.bam'
    output:
        'output/{dir}/{group}.bam.bai'
    shell:
        'samtools index {input}'


rule index_fasta:
    input:
        fasta = 'output/{dir}/{group}.fasta'
    output:
        'output/{dir}/{group}.fasta.fai',
        'output/{dir}/{group}.rev.2.bt2',
        'output/{dir}/{group}.fasta.amb',
        'output/{dir}/{group}.dict',
        'output/{dir}/{group}.3.bt2',
        'output/{dir}/{group}.rev.1.bt2',
        'output/{dir}/{group}.fasta.pac',
        'output/{dir}/{group}.2.bt2',
        'output/{dir}/{group}.fasta.sa',
        'output/{dir}/{group}.1.bt2',
        'output/{dir}/{group}.fasta.ann',
        'output/{dir}/{group}.4.bt2',
        'output/{dir}/{group}.fasta.bwt'
    run:
        index_prefix = os.path.splitext(input.fasta)[0]
        picard_dict = index_prefix + '.dict'
        shell(' '.join(['bowtie2-build', input.fasta, index_prefix]))
        shell(' '.join(['samtools', 'faidx', input.fasta]))
        shell('picard CreateSequenceDictionary R=' + input.fasta +
              ' O=' + picard_dict)
        shell('bwa index {input}')


rule align_to_assembly:
    input:
        unpack(match_reads),
        unpack(match_assembly)
    output:
        bam = 'output/align_to_assembly{iter}/{sample}.bam'
    threads: 12
    resources:
        mem_mb = 20000
    params:
        max_insert = 1000
    log:
        "output/align_to_assembly{iter}/log/{sample}.log"
    run:
        index_prefix = os.path.splitext(input.assembly)[0]
        if wildcards.iter in ['_masked', '_unmasked']:
            shell('bwa mem '
                  '-t {threads} ' +
                  '{input.assembly} '
                  '-R "@RG\\tID:{wildcards.sample}\\tLIB:{wildcards.sample}\\t'
                  'SM:{wildcards.sample}\\tPL:illumina" '
                  '{input.fwd_reads} {input.rev_reads} | '
                  'samtools view -bh - | '
                  'samtools sort - > {output.bam} 2> {log}')
        else:
            shell('bowtie2 -1 {input.fwd_reads} -2 {input.rev_reads} '
                  '-U {input.unpaired_reads} -X {params.max_insert} '
                  '-x ' + index_prefix + ' --rg-id={wildcards.sample} '
                  '--rg=LIB:{wildcards.sample} --rg=PL:illumina '
                  '--rg=SM:{wildcards.sample} -p {threads} | '
                  'samtools view -bh - | '
                  'samtools sort - > {output.bam} 2> {log}')


rule vcf_to_tab:
    input:
        unpack(match_assembly),
        vcf = 'output/{dir}/{sample}.{vartype}.vcf'
    output:
        'output/{dir}/{sample}.{vartype}.vcf.tsv'
    shell:
        'gatk VariantsToTable '
        '-R {input.ref} '
        '-V {input.vcf} '
        '-O {output} '
        '-F CHROM -F POS -GF GT -F QUAL -F MQ -F DP -F TRANSTION -GF AD '
        '-F "HOM-REF" -F "HOM-VAR" -F TYPE'
# }}}


# ==============================================================================
# Build extra input files
# ==============================================================================
# {{{
rule build_diamond_database:
    output:
        "output/build_diamond_database/uniprot_ref_proteomes.fasta",
        "output/build_diamond_database/uniprot_ref_proteomes.dmnd",
        "output/build_diamond_database/uniprot_ref_proteomes.taxids"
    threads: 16
    script:
        "scripts/build_diamond_database.py"
# }}}

# ==============================================================================
# Quality Control / Trimming
# ==============================================================================
# {{{

rule trim_adapters:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        fwd_reads = temp('output/trim_adapters/{sample}.R1.fastq.gz'),
        rev_reads = temp('output/trim_adapters/{sample}.R2.fastq.gz')
    log: "output/trim_adapters/log/{sample}.log"
    threads: 10
    params:
        ref = config['adapters'],
        k = '23',
        ktrim = 'r',
        mink = '4',
        hdist = '1'
    shell:
        'bbduk.sh '
        'in={input.fwd_reads} in2={input.rev_reads} '
        'threads={threads} '
        'out={output.fwd_reads} out2={output.rev_reads} '
        'ref={params.ref} '
        'k={params.k} '
        'ktrim={params.ktrim} '
        'mink={params.mink} '
        'hdist={params.hdist} '
        'tpe tbo 2> {log}'


rule merge_reads:
    input:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/merge_reads/{sample}.R1.fastq.gz',
        rev_reads = 'output/merge_reads/{sample}.R2.fastq.gz',
        merged_reads = 'output/merge_reads/{sample}.unpaired.fastq.gz',
        insert_hist = 'output/merge_reads/{sample}.hist'
    log:
        'output/merge_reads/log/{sample}.log'
    threads: 12
    params:
        vstrict = 't'
    shell:
        'bbmerge.sh '
        'in1={input.fwd_reads} in2={input.rev_reads} '
        'threads={threads} '
        'out={output.merged_reads} '
        'outu={output.fwd_reads} outu2={output.rev_reads} '
        'ihist={output.insert_hist} '
        'vstrict={params.vstrict} 2> {log}'


rule quality_trim:
    input:
        fwd_reads = 'output/merge_reads/{sample}.R1.fastq.gz',
        rev_reads = 'output/merge_reads/{sample}.R2.fastq.gz',
        merged_reads = 'output/merge_reads/{sample}.unpaired.fastq.gz',
    output:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        merged_reads = 'output/quality_trim/{sample}.unpaired.fastq.gz'
    log:
        paired = 'output/quality_trim/log/{sample}.paired.log',
        unpaired = 'output/quality_trim/log/{sample}.unpaired.log'
    threads: 10
    params:
        qtrim = 'rl',
        trimq = '20',
        minlen = '50'
    run:
        shell('bbduk.sh '
              'in={input.fwd_reads} in2={input.rev_reads} '
              'out={output.fwd_reads} out2={output.rev_reads} '
              'threads={threads} '
              'qtrim={params.qtrim} '
              'trimq={params.trimq} '
              'minlen={params.minlen} 2> {log.paired}')
        shell('bbduk.sh '
              'in={input.merged_reads} '
              'out={output.merged_reads} '
              'qtrim={params.qtrim} '
              'trimq={params.trimq} '
              'minlen={params.minlen} '
              'threads={threads} 2> {log.unpaired}')
# }}}

# ==============================================================================
# Assembly-Decontamination Iterations
# ==============================================================================
# {{{

rule assembly:
    input:
        unpack(match_reads)
    output:
        assembly = 'output/assembly{iter}/{genotype}SC.fasta'
    threads: 8
    resources:
        mem_mb = 150000
    run:
        outdir = local.path('output') / ('assembly' + wildcards.iter)
        clear_directory(outdir)
        shell(
            'python2 util/spades/bin/spades.py '
            '-1 {input.fwd_reads} -2 {input.rev_reads} '
            '-s {input.unpaired_reads} '
            '--threads {threads} '
            '-o ' + str(outdir))
        (outdir / 'scaffolds.fasta').move(output.assembly)

rule length_filter_assembly:
    input:
        lambda wildcards: (
            ''.join(['output/filter_contamination_reduced/',
                     wildcards.genotype, 'SC.fasta'])
            if wildcards.iter in ['_reduced', '_unmasked', '_masked'] else
            ''.join(['output/assembly', wildcards.iter, '/', wildcards.genotype,
                     'SC.fasta']))
    output:
        'output/length_filter_assembly{iter}/{genotype}SC.fasta'
    run:
        if wildcards.iter == '_reduced':
            minlen = '1000'
        else:
            minlen = '200'
        shell('length_filter_fasta.pl ' + minlen + ' {input} > {output}')

rule blast_assembly:
    input:
        unpack(match_assembly)
    output:
        'output/blast_assembly{iter}/{genotype}SC.tsv'
    threads: 10
    params:
        max_target_seqs = '5',
        evalue = '1e-25',
        max_hsps = '1',
    shell:
        'blastn '
        '-db {config[blast_database]} '
        '-task megablast '
        '-max_target_seqs {params.max_target_seqs} '
        '-max_hsps {params.max_hsps} '
        '-evalue {params.evalue} '
        '-query {input} '
        '-out {output} '
        '-outfmt \'6 qseqid staxids bitscore std\' '
        '-num_threads {threads}'


rule diamond_blast_assembly:
    input:
        unpack(match_assembly),
        db = 'output/build_diamond_database/uniprot_ref_proteomes.dmnd'
    output:
        'output/diamond_blast_assembly{iter}/{genotype}SC.out'
    params:
        max_target_seqs = '1',
        evalue = '1e-25'
    threads: 16
    resources:
        mem_mb = 50000
    shell:
        'diamond blastx '
        '--query {input.assembly} '
        '--max-target-seqs {params.max_target_seqs} '
        '--threads {threads} '
        '--sensitive '
        '--db {input.db} '
        '--evalue {params.evalue} '
        '--outfmt 6 '
        '--out {output}'

rule taxify_diamond_blasts:
    input:
        diamond_hits = 'output/diamond_blast_assembly{iter}/{genotype}SC.out',
        taxids = 'output/build_diamond_database/uniprot_ref_proteomes.taxids'
    output:
        'output/diamond_blast_assembly{iter}/{genotype}SC.taxified.out',
    params:
        output_prefix = 'output/diamond_blast_assembly{iter}/'
    shell:
        'blobtools taxify -f {input.diamond_hits} -m {input.taxids} -s 0 -t 2 '
        '-o {params.output_prefix}'


rule convert_alignment_to_cov:
    input:
        unpack(match_assembly),
        bam = 'output/align_to_assembly{iter}/{sample}.bam',
        bai = 'output/align_to_assembly{iter}/{sample}.bam.bai',
    output:
        'output/convert_alignment_to_cov{iter}/{sample}.bam.cov'
    resources:
        mem_mb = 20000
    params:
        output_prefix = 'output/convert_alignment_to_cov{iter}/'
    log:
        'output/convert_alignment_to_cov{iter}/logs/{sample}.log'
    shell:
        'blobtools map2cov '
        '-i {input.assembly} '
        '-b {input.bam} '
        '-o {params.output_prefix} 2> {log}'

rule init_blobtools_database:
    input:
        unpack(match_assembly),
        blast_hits = 'output/blast_assembly{iter}/{genotype}SC.tsv',
        covs = lambda wildcards: [
            '/'.join([
                'output/convert_alignment_to_cov' + wildcards.iter,
                smp + '.bam.cov'])
            for smp in GENOTYPE_TO_SAMPLE[wildcards.genotype]],
        diamond_hits = (
            'output/diamond_blast_assembly{iter}/{genotype}SC.taxified.out')
    output:
        'output/init_blobtools_database{iter}/{genotype}.blobDB.json'
    resources:
        mem_mb = 20000
    params:
        output_prefix = 'output/init_blobtools_database{iter}/{genotype}'
    log:
        'output/init_blobtools_database{iter}/log/{genotype}.log'
    run:
        cov_args = '-c ' + ' -c '.join(input.covs)
        shell('blobtools create '
              '-i {input.assembly} '
              '--title {wildcards.genotype} '
              '--out {params.output_prefix} '
              '--hitsfile {input.blast_hits} --hitsfile {input.diamond_hits} '
              '--nodes {config[nodes_dmp]} --names {config[names_dmp]} ' +
              cov_args + ' > {log} 2>&1')

rule produce_blobplots:
    input:
        db = 'output/init_blobtools_database{iter}/{genotype}.blobDB.json'
    output:
        ('output/produce_blobplots{iter}/{genotype}/family/{genotype}.bestsum.'
         'family.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/genus/{genotype}.bestsum.'
         'genus.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/order/{genotype}.bestsum.'
         'order.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/phylum/{genotype}.bestsum.'
         'phylum.p20.span.100.blobplot.cov0.png'),
        ('output/produce_blobplots{iter}/{genotype}/species/{genotype}.bestsum.'
         'species.p20.span.100.blobplot.cov0.png')
    threads: 5
    resources:
        mem_mb = 40000
    params:
        outdir = 'output/produce_blobplots{iter}/{genotype}'
    run:
        processes = []
        for rank in ['family', 'genus', 'order', 'phylum', 'species']:
            outdir = params.outdir + '/' + rank + '/'
            processes.append(
                blobtools.popen([
                    'blobplot', '-p', '20', '-r', rank, '-i', input.db, '-o',
                    outdir]))
        for process in processes:
            process.join()

rule produce_covplots:
    input:
        cov = 'output/convert_alignment_to_cov{iter}/{sample}.bam.cov',
        db = lambda wildcards: '/'.join([
            'output/init_blobtools_database' + wildcards.iter,
            get_genotype(wildcards) + '.blobDB.json'])
    output:
        'output/produce_covplots{iter}/{sample}.covsum.png'
    params:
        output_prefix = 'output/produce_covplots{iter}/{sample}',
        rank = 'superkingdom'
    run:
        shell('blobtools covplot -p 20 -c {input.cov} '
              '-i {input.db} -r {params.rank} '
              '-o {params.output_prefix}')

        outdir = local.path(params.output_prefix).dirname
        output_files = outdir.glob(wildcards.sample + '*')
        for f in output_files:
            extensions = '.'.join(f.name.split('.')[-2:])
            newname = outdir / (wildcards.sample + '.' + extensions)
            f.move(newname)

rule produce_blobtable:
    input:
        db = 'output/init_blobtools_database{iter}/{genotype}.blobDB.json'
    output:
        'output/produce_blobtable{iter}/{genotype}.blobDB.bestsum.table.txt'
    params:
        outdir = 'output/produce_blobtable{iter}/'
    shell:
        'blobtools view -r all -b -i {input.db} -o {params.outdir}'


rule find_contam_contigs:
    input:
        'output/produce_blobtable{iter}/{genotype}.blobDB.bestsum.table.txt'
    output:
        'output/find_contam_contigs{iter}/{genotype}.txt'
    shell:
        'scripts/find_contam_contigs{wildcards.iter}.R {input} > {output}'


# List the contigs which passed the filtering step
rule generate_inclusion_list:
    input:
        unpack(match_filter_alignment),
        exclusions = lambda wildcards: (
            'output/find_mitochondrial_scaffolds/{genotype}.txt'
            if wildcards.iter == '_reduced'
            else ''.join(['output/find_contam_contigs', wildcards.iter,
                          '/{genotype}.txt']))
    output:
        'output/generate_inclusion_list{iter}/{genotype}.txt'
    shell:
        'list_csomes {input.assembly} | '
        'complement.sh /dev/stdin {input.exclusions} > {output}'


rule filter_contamination:
    input:
        unpack(match_filter_alignment),
        passing_contigs = lambda wildcards: '/'.join([
            'output/generate_inclusion_list' + wildcards.iter,
            get_genotype(wildcards) + '.txt']),
    output:
        fwd = 'output/filter_contamination{iter}/{sample}.R1.fastq.gz',
        rev = 'output/filter_contamination{iter}/{sample}.R2.fastq.gz',
        unpaired = (
            'output/filter_contamination{iter}/{sample}.unpaired.fastq.gz')
    threads: 16
    resources:
        mem_mb = 60000
    params:
        output_prefix = 'output/filter_contamination{iter}/{sample}'
    log:
        'output/filter_contamination{iter}/logs/{sample}.log'
    run:
        # This step removes all reads which are not mapped to a contig in the
        # inclusion list (this includes unmapped reads).
        shell('extract_csomes.py '
              '-n 200 '
              '-p {threads} '
              '-o {params.output_prefix} '
              '-i {input.passing_contigs} '
              '-f fastq {input.bam} 2> {log}')

        outdir = local.path(output.unpaired).dirname
        tmp = outdir / (uuid4().hex + '.fastq.gz')
        # Remove all unpaired reads which are not merged
        shell("zcat {output.unpaired} | "
              "paste - - - - | "
              "awk 'length($2) >= 151' | sed 's/\\t/\\n/g' | "
              "gzip - > " + str(tmp))
        tmp.move(output.unpaired)

# }}}

# ==============================================================================
# Reduction/Scaffolding
# ==============================================================================
# {{{

rule redundans:
    input:
        fwd_reads = 'output/filter_contamination2/{genotype}SC.R1.fastq.gz',
        rev_reads = 'output/filter_contamination2/{genotype}SC.R2.fastq.gz',
        unpaired_reads = (
            'output/filter_contamination2/{genotype}SC.unpaired.fastq.gz'),
        assembly = 'output/assembly3/{genotype}SC.fasta'
    output:
        fasta = 'output/redundans/{genotype}SC.fasta'
    params:
        outdir = 'output/redundans/{genotype}'
    threads: 16
    resources:
        mem_mb = 100000
    log:
        'output/redundans/log/{genotype}.log'
    run:
        clear_directory(params.outdir)
        shell('rm -rf {params.outdir}')
        shell('python2 {config[redundans_bin]} -v -f {input.assembly} '
              '-i {input.fwd_reads} {input.rev_reads} {input.unpaired_reads} '
              '-o {params.outdir} '
              '-r {config[nuclear_reference]} '
              '-t {threads} '
              '--usebwa 2> {log}')
        (local.path(params.outdir) / 'scaffolds.reduced.fa').move(output.fasta)

rule blast_against_mitochondria:
    input:
        'output/redundans/{genotype}SC.fasta'
    output:
        list = 'output/blast_against_mitochondria/{genotype}.txt',
        blast = 'output/blast_against_mitochondria/{genotype}.tsv'
    run:
        # BLAST assembly vs. mtdna
        shell('blastn -subject {input} '
              '-query {config[mitochondrial_reference]} '
              '-num_alignments 10 -outfmt 6 > {output.blast}')
        # Get the contig names
        shell('cat {output.blast} | cut -f 2 | uniq -d > {output.list}')

rule filter_mitochondrial_scaffolds:
    input:
        blast = 'output/blast_against_mitochondria/{genotype}.tsv',
        assembly = 'output/redundans/{genotype}SC.fasta'
    output:
        fasta = 'output/find_mitochondrial_scaffolds/{genotype}.fasta',
        txt = 'output/find_mitochondrial_scaffolds/{genotype}.txt'
    shell:
        'scripts/filter_mitochondrial_scaffolds.py '
        '--blast {input.blast} '
        '--assembly {input.assembly} '
        '--outfasta {output.fasta} '
        '--outtxt {output.txt}'

rule repeatmasker:
    input:
        'output/length_filter_assembly_reduced/{genotype}SC.fasta'
    output:
        masked = 'output/repeatmasker/{genotype}SC.fasta',
        out = 'output/repeatmasker/{genotype}SC.out'
    threads: 8
    run:
        shell('RepeatMasker '
              '-lib {config[repeat_library]} '
              '-s '
              '-par {threads} '
              '{input}')
        input_dir = local.path(input).dirname
        output_dir = local.path(output.masked).dirname
        tmp_outputs = [input_dir / (wildcards.genotype + 'SC' + suffix)
                       for suffix in ['.fasta.masked', '.fasta.out']]
        for tmp, final in zip(tmp_outputs, output):
            tmp.move(final)

# }}}

# ==============================================================================
# Variant Calling Pre-Processing
# ==============================================================================
# {{{

rule mark_duplicates:
    input:
        bam = 'output/align_to_assembly{iter}/{sample}.bam',
        bai = 'output/align_to_assembly{iter}/{sample}.bam.bai'
    output:
        bam = 'output/mark_duplicates{iter}/{sample}.bam',
        logfile = 'output/mark_duplicates{iter}/log/{sample}.log'
    resources:
        mem_mb = 30000
    log:
        'output/mark_duplicates/log/{sample}.log'
    shell:
        'picard MarkDuplicates '
        'I={input.bam} '
        'O={output.bam} '
        'REMOVE_DUPLICATES=True '
        'M={log}'

# }}}

# ==============================================================================
# Variant Calling
# ==============================================================================
# {{{
rule call_variants:
    input:
        unpack(match_assembly),
        bam = 'output/mark_duplicates_masked/{sample}.bam',
        bai = 'output/mark_duplicates_masked/{sample}.bam.bai',
    output:
        gvcf = 'output/call_variants{call}/{sample}.g.vcf'
    resources:
        mem_mb = 20000
    params:
        snp_heterozygosity = 0.015,
        indel_heterozygosity = 0.01
    log:
        'output/call_variants{iter}/log/{sample}.log'
    shell:
        'gatk HaplotypeCaller '
        '-R {input.assembly} '
        '-I {input.bam} '
        '--emit-ref-confidence GVCF '
        '-O {output} '
        '--heterozygosity {params.snp_heterozygosity} '
        '--output-mode EMIT_ALL_SITES '
        '--indel-heterozygosity {params.indel_heterozygosity} '

rule genotype_gvcfs:
    input:
        unpack(match_assembly),
        gvcf = 'output/call_variants{call}/{sample}.g.vcf',
    output:
        'output/genotype_gvcfs{call}/{sample}.vcf'
    params:
        snp_heterozygosity = 0.015,
        indel_heterozygosity = 0.01
    shell:
        'gatk GenotypeGVCFs '
        '-R {input.ref} '
        '-V {input.gvcf} '
        '-O {output} '
        '--heterozygosity {params.snp_heterozygosity} '
        '--indel-heterozygosity {params.indel_heterozygosity} '

rule extract_variant_coverage:
    input:
        'output/genotype_gvcfs{call}/{sample}.vcf'
    output:
        'output/extract_variant_coverage{iter}/{sample}.txt',
    shell:
        'extract_variant_coverage.py -o {output} {input}'

rule select_variants:
    input:
        unpack(match_assembly),
        vcf = 'output/genotype_gvcfs{call}/{sample}.vcf',
    output:
        'output/select_variants{call}/{sample}.{vartype}.vcf'
    run:
        if wildcards.vartype == 'snps':
            criteria = '--select-vartype-to-include SNP'
        elif wildcards.vartype == 'indels':
            criteria = '--select-vartype-to-include INDEL'
        elif wildcards.vartype == 'other':
            criteria = (
                '--select-vartype-to-exclude SNP --select-vartype-to-exclude INDEL')
        shell('gatk SelectVariants '
              '-R {input.assembly} '
              '-V {input.vcf} '
              '-O {output} ' +
              criteria)

rule exclude_nonvariants:
    input:
        unpack(match_assembly),
        vcf = 'output/select_variants{call}/{sample}.{vartype}.vcf',
    output:
        vcf = 'output/exclude_nonvariants{call}/{sample}.{vartype}.vcf',
        table = 'output/exclude_nonvariants{call}/{sample}.{vartype}.vcf.tsv'
    shell:
        'gatk SelectVariants '
        '-R {input.assembly} '
        '-V {input.vcf} '
        '--exclude-non-variants '
        '-O {output.vcf}'

rule extract_variant_quality_scores:
    input:
        unpack(match_assembly),
        vcf = 'output/select_variants{call}/{sample}.{vartype}.vcf'
    output:
        'output/extract_variant_quality_scores{call}/{sample}.{vartype}.q.tsv'
    shell:
        'gatk VariantsToTable '
        '-R {input.assembly} '
        '-V {input.vcf} '
        '-F CHROM -F QUAL -F QD -F DP -F MQ -F MQRankSum -F FS '
        '-F ReadPosRankSum -F SOR '
        '-O {output}'

rule plot_variant_quality_scores:
    input:
        snps = (
            'output/extract_variant_quality_scores{call}/{sample}.snps.q.tsv'),
        indels = (
            'output/extract_variant_quality_scores{call}/{sample}.indels.q.tsv')
    output:
        'output/plot_variant_quality_scores{call}/{sample}.svg'
    script:
        'scripts/plot_variant_quality_scores.R'


rule filter_variants:
    input:
        unpack(match_assembly),
        vcf = 'output/select_variants{call}/{sample}.{vartype}.vcf',
    output:
        'output/filter_variants{call}/{sample}.{vartype}.vcf'
    params:
    run:
        if wildcards.vartype == 'snps':
            filters = {
                'QD': '< 2.0',
                'FS': '> 60.0',
                'MQ': '< 35.0',
                'SOR': '> 4.0',
                'MQRankSum': '< -12.5',
                'ReadPosRankSum': ['< -10.0', '> 10.0']
            }
        elif wildcards.vartype in ['indels', 'other']:
            filters = {
                'QD': '< 5.0',
                'FS': '> 200.0',
                'QUAL': '< 100.0',
                'SOR': '> 10.0',
                'ReadPosRankSum': ['< -10.0', '> 10.0']
            }
        filter_expression = build_filter_expression(filters)
        shell('gatk VariantFiltration '
              '-R {input.assembly} '
              '-V {input.vcf} '
              '-O {output} '
              '--filter-name snp_filter '
              '--filter-expression ' + filter_expression)

rule calc_number_filtered_sites:
    input:
        pre = 'output/select_variants{call}/{sample}.{vartype}.vcf',
        post = 'output/filter_variants{call}/{sample}.{vartype}.vcf'
    output:
        'output/calc_number_filtered_sites{call}/{sample}.{vartype}.txt'
    shell:
        'echo "Sites prefilter: " >> {output}; '
        'grep -vc "^#" {input.pre} >>  {output}; '
        'echo "\nSites postfilter: " >> {output}; '
        'grep -vc "^#" {input.post} >> {output}'

rule depth_filter_variants:
    input:
        unpack(match_assembly),
        vcf = 'output/filter_variants{call}/{sample}.{vartype}.vcf',
    output:
        vcf = 'output/depth_filter_variants{call}/{sample}.{vartype}.vcf'
    shell:
        'gatk VariantFiltration '
            '-R {input.assembly} '
            '-V {input.vcf} '
            '-O {output.vcf} '
            '--filter-name depth_filter '
            '--filter-expression "DP < 10 || DP > 100"'

rule remove_filtered_variants:
    input:
        unpack(match_assembly),
        vcf = 'output/depth_filter_variants{call}/{sample}.{vartype}.vcf',
    output:
        'output/remove_filtered_variants{call}/{sample}.{vartype}.vcf'
    shell:
        'gatk SelectVariants '
        '-R {input.assembly} '
        '-V {input.vcf} '
        '-O {output} '
        '--exclude-filtered '
        '--exclude-non-variants'

rule select_unique_variants:
    input:
        filtered = expand(
            'output/remove_filtered_variants{{call}}/{sample}.{{vartype}}.vcf.tsv',
            sample=SAMPLE),
        unfiltered = expand(
            'output/exclude_nonvariants{{call}}/{sample}.{{vartype}}.vcf.tsv',
            sample=SAMPLE)
    output:
        expand('output/select_unique_variants{{call}}/{sample}.{{vartype}}.vcf.tsv',
                sample=SAMPLE)
    run:
        # Remove all sites in each filtered sample which are also present in any
        # unfiltered sample of the same genotype.
        output_prefix = os.path.dirname(output[0]) + '/'
        for genotype in GENOTYPE:
            genotype_samples = GENOTYPE_TO_SAMPLE[genotype]
            filtered_files = []
            for f in input.filtered:
                if any(substr in f for substr in genotype_samples):
                    filtered_files.append(f)

            for target in filtered_files:
                comparisons = []
                for f in input.unfiltered:
                    if (any(substr in f for substr in genotype_samples) and
                            local.path(target).name != local.path(f).name):
                        comparisons.append(f)

                shell('complement.py '
                      '-o ' + output_prefix + ' '
                      '--tab_separated '
                      '-i 0,1,9 '
                      '--target ' + target + ' ' +
                      ' '.join([target] + comparisons))

# }}}

# ==============================================================================
# Summarize Pipeline
# ==============================================================================
# {{{

rule raw_fastqc:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        'output/raw_fastqc/{sample}.R1_fastqc.zip',
        'output/raw_fastqc/{sample}.R2_fastqc.zip',
    params:
        outdir = 'output/raw_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads}"

rule clean_fastqc:
    input:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz',
        unpaired_reads = 'output/quality_trim/{sample}.unpaired.fastq.gz'
    output:
        'output/clean_fastqc/{sample}.R1_fastqc.zip',
        'output/clean_fastqc/{sample}.R2_fastqc.zip',
        'output/clean_fastqc/{sample}.unpaired_fastqc.zip'
    params:
        outdir = 'output/clean_fastqc'
    shell:
        'fastqc '
        '-o {params.outdir} '
        '{input.fwd_reads} {input.rev_reads} {input.unpaired_reads}'


rule quast:
    input:
        unpack(match_reads), unpack(match_assembly)
    output:
        'output/quast{iter}/{genotype}/report.tsv'
    threads: 6
    params:
        outdir = "output/quast{iter}/{genotype}"
    resources:
        mem_mb = 40000
    shell:
        'quast.py '
        '-o {params.outdir} '
        '--eukaryote '
        '-1 {input.fwd_reads} -2 {input.rev_reads} '
        '-t {threads} '
        '--no-snps {input.assembly}'

rule qualimap:
    input:
        'output/align_to_assembly_unmasked/{sample}.bam'
    output:
        'output/qualimap/{sample}/genome_results.txt'
    threads: 8
    shell:
        'qualimap bamqc '
        '-nt {threads} '
        '-bam {input} '
        '-outdir output/qualimap/{wildcards.sample}'

rule busco:
    input:
        unpack(match_assembly)
    output:
        'output/busco{iter}/{genotype}/short_summary_{genotype}.txt'
    params:
        outdir = 'output/busco{iter}/{genotype}'
    run:
        outdir = local.path(params.outdir)
        clear_directory(outdir)
        outdir_root = outdir.dirname
        local.env['BUSCO_CONFIG_FILE'] = local.path(config['busco_config'])
        local.env['AUGUSTUS_CONFIG_PATH'] = local.path(
            config['augustus_config'])
        local.env['PATH'] = ':'.join([
            local.path(config['augustus_scripts']), local.env['PATH']
        ])
        assembly = local.path(input.assembly)
        lineage_file = local.path(config['busco_database'])
        tmp_outdir = outdir_root / ('run_' + wildcards.genotype)

        with local.cwd(outdir_root):
            busco['-i', assembly, '-o', wildcards.genotype, '-l', lineage_file,
                  '-m', 'geno', '-f'] & FG
            for f in tmp_outdir.list():
                f.move(outdir)
            tmp_outdir.delete()

rule samtools_stats:
    input:
        'output/align_to_assembly_unmasked/{sample}.bam'
    output:
        'output/samtools_stats/{sample}.stats'
    shell:
        'samtools stats {input} > {output}'

rule multiqc:
    input:
        expand('output/{stage}_fastqc/{sample}.{dir}_fastqc.zip', sample=SAMPLE,
                dir=['R1', 'R2'], stage=['raw', 'clean']),
        expand('output/clean_fastqc/{sample}.unpaired_fastqc.zip',
               sample=SAMPLE),
        expand('output/merge_reads/{sample}.hist', sample=SAMPLE),
        expand('output/quast{iter}/{genotype}/report.tsv',
               iter=PLOT_ITER, genotype=GENOTYPE),
        expand('output/busco{iter}/{genotype}/short_summary_{genotype}.txt',
               iter=PLOT_ITER, genotype=GENOTYPE),
        expand('output/mark_duplicates{iter}/log/{sample}.log',
               sample=SAMPLE, iter=['_masked', '_unmasked']),
        expand('output/samtools_stats/{sample}.stats', sample=SAMPLE),
        expand('output/qualimap/{sample}/genome_results.txt', sample=SAMPLE),
    output:
        'output/multiqc/multiqc.html'
    shell:
        'multiqc -f -d -n {output} {input}'
# }}}
